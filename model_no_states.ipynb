{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#PLOT & MATH LIBS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Research wrap up\n",
    "##### ON OFF States\n",
    "1. Same idea as originally (one-hot) BUT:\n",
    "   1. Keep Same Month Visits, then select randomly from total visits\n",
    "   2. In the case with both ON & OFF for the same visit\n",
    "      1. Record the scores in an extra column so, u_on_0, u_off_o oooooorrrr\n",
    "      2. **Duplicate the row, keeping all other entries the same, but with the ON & OFF entry different for each**\n",
    "      3. Make Sure both of either same month or ON & OFF are in the same training or validation set\n",
    "   3. Compare One-to-one with completely random selection from fist analysis (but including same month visits)\n",
    "\n",
    "\n",
    "##### De-noising\n",
    "1. Use calendar approach:\n",
    "   1. Divide the PATNO's interval into 3 non-overlapping >6mo periods\n",
    "   2. Take the mean of each interval as the interval UPDRS score\n",
    "   3. Take the mean(median Date) as the date for that interval (if >1 date within!)\n",
    "3.  Compare results vs calendar approach for random choice for both (i.e. random selection within same intervals)\n",
    "\n",
    "#### BOTH\n",
    "- Have the underlying entry selection and structure be the same for baseline and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_date_calc(date_group: pd.DataFrame, interval: pd.Timedelta) -> list:\n",
    "    dates = date_group['INFODT'].tolist()\n",
    "    date1 = dates[0] + interval / 2\n",
    "    date2 = dates[1] + interval / 2\n",
    "    date3 = dates[2] + interval / 2\n",
    "    return [(date1-date1).days, (date2-date1).days, (date3-date1).days]\n",
    "\n",
    "def interpolate_same_month(df: pd.DataFrame, method = 'rand') -> pd.DataFrame:\n",
    "    # Select maximum score from same month measurements\n",
    "    temp_df = df.copy()\n",
    "    temp_df['YEAR_MONTH'] = temp_df['INFODT'].dt.to_period('M')\n",
    "\n",
    "    #takes random selctions/maximum/minimum/mean of values which share same month and year\n",
    "    if method == 'rand':\n",
    "        sample = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].apply(lambda x: x.sample(1)).reset_index()\n",
    "        result = pd.merge(temp_df, sample, on=['PATNO', 'YEAR_MONTH', 'NP3TOT'])\n",
    "\n",
    "        result.drop(columns=['YEAR_MONTH', 'level_2'], inplace=True)\n",
    "        return result.drop_duplicates(subset=['PATNO', 'INFODT']).reset_index(drop=True)\n",
    "\n",
    "    elif method == 'min':\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('min')\n",
    "    elif method == 'max':\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('max')\n",
    "    else:\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('mean')\n",
    "\n",
    "    \n",
    "    temp_df.drop(columns=['YEAR_MONTH'], inplace=True)\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "    return temp_df.drop_duplicates(subset=['PATNO', 'INFODT'])\n",
    "\n",
    "def pivot_wide(df: pd.DataFrame, cols: int = 3) -> pd.DataFrame:\n",
    "\n",
    "    df['time_index'] = (\n",
    "            df.groupby('PATNO')['INFODT']\n",
    "            .rank(method='first')\n",
    "            .astype(int)-1\n",
    "        ) \n",
    "    \n",
    "    time_df = df[['PATNO', 'INFODT', 'time_index']]\n",
    "\n",
    "    score_wide = df.pivot(\n",
    "        index='PATNO',\n",
    "        columns='time_index',\n",
    "        values='NP3TOT'\n",
    "    ).reset_index()\n",
    "\n",
    "    time_wide = time_df.pivot(\n",
    "        index='PATNO',\n",
    "        columns=\"time_index\",\n",
    "        values='INFODT'\n",
    "    ).reset_index()\n",
    "\n",
    "    score_wide.columns = ['PATNO'] + [f'u{i}' for i in range(cols)] # resets score column names correctly\n",
    "    time_wide.columns = ['PATNO'] + [f't{i}' for i in range(cols)] # resets time_index column names accordingly\n",
    "\n",
    "    merged = pd.merge(score_wide, time_wide, on='PATNO')\n",
    "    merged.drop(columns='PATNO', inplace=True)\n",
    "\n",
    "    new_cols = []\n",
    "    for i in range(cols): # re order columns for ML piplines\n",
    "        new_cols.append(f't{i}')\n",
    "        new_cols.append(f'u{i}')\n",
    "\n",
    "    merged = merged[new_cols]\n",
    "\n",
    "    return merged.drop(columns='t0')\n",
    "\n",
    "\n",
    "\n",
    "# keep_small_intervals flag allows us to keep some entries with <6mo intervals\n",
    "# assumes process_same_dates has already been calles\n",
    "def process_mean_intervals(df: pd.DataFrame, blocks: int = 3, keep_small_intervals = True) -> pd.DataFrame:\n",
    "    patnos = df['PATNO'].unique().tolist()\n",
    "    result = pd.DataFrame(columns=['PATNO', 'INFODT', 'NP3TOT'])\n",
    "    for patno in patnos:\n",
    "        df_pat = df[df['PATNO'] == patno]\n",
    "        start = df_pat['INFODT'].min()\n",
    "        end = df_pat['INFODT'].max()\n",
    "        diff = end - start\n",
    "\n",
    "        if (diff < pd.Timedelta(days=180)) or (df_pat.index.size < 3):\n",
    "            continue\n",
    "\n",
    "        interval = diff // blocks\n",
    "\n",
    "        # drop small intervals < 6mo\n",
    "        if not keep_small_intervals and interval < pd.Timedelta(days=180):\n",
    "            continue\n",
    "\n",
    "        group_counts = df_pat.groupby(pd.Grouper(key='INFODT', freq= f'{interval.days+1}D'))['NP3TOT'].count()\n",
    "        temp = df_pat.groupby(pd.Grouper(key='INFODT', freq= f'{interval.days+1}D'))['NP3TOT'].mean().reset_index()\n",
    "        temp['group_counts'] = group_counts.values\n",
    "        # checks for Failed Time Group Function \n",
    "        if temp['NP3TOT'].isnull().values.any():\n",
    "            continue\n",
    "        \n",
    "        dates = median_date_calc(df_pat.groupby(pd.Grouper(key='INFODT', freq= f'{interval.days}D'))['NP3TOT'].mean().reset_index(), interval)\n",
    "\n",
    "        # this logic will create some entries with < 6mo intervals, but this is only due to the abover grouper function using a slightly different calendar\n",
    "        temp['INFODT'] = dates\n",
    "        temp['PATNO'] = patno\n",
    "\n",
    "        result = pd.concat([result, temp], ignore_index=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_random_intervals(df: pd.DataFrame, blocks: int = 3, keep_small_intervals = True) -> pd.DataFrame:\n",
    "    patnos = df['PATNO'].unique().tolist()\n",
    "    patnos = df['PATNO'].unique().tolist()\n",
    "    result = pd.DataFrame(columns=['PATNO', 'INFODT', 'NP3TOT'])\n",
    "    for patno in patnos:\n",
    "        df_pat = df[df['PATNO'] == patno]\n",
    "        start = df_pat['INFODT'].min()\n",
    "        end = df_pat['INFODT'].max()\n",
    "        diff = end - start\n",
    "\n",
    "        if (diff < pd.Timedelta(days=180)) or (df_pat.index.size < 3):\n",
    "            continue\n",
    "\n",
    "        interval = diff // blocks\n",
    "\n",
    "        # drop small intervals < 6mo\n",
    "        if not keep_small_intervals and interval < pd.Timedelta(days=180):\n",
    "            continue\n",
    "\n",
    "        temp = (\n",
    "            df_pat.groupby(pd.Grouper(key='INFODT', freq=f'{interval.days+1}D'))['NP3TOT']\n",
    "            .apply(lambda x: x.sample(n=1, random_state=1) if len(x) > 0 else None)\n",
    "            .dropna()  # Drop groups where no sample was taken (i.e., empty groups)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # checks for Failed Time Group Function // when the groupby function can't return 3 groups (like it should)\n",
    "        if temp.index.size != 3:\n",
    "            #print(\"Failed Time Group Function\")\n",
    "            continue\n",
    "\n",
    "        dates = median_date_calc(df_pat.groupby(pd.Grouper(key='INFODT', freq= f'{interval.days}D'))['NP3TOT'].mean().reset_index(), interval)\n",
    "\n",
    "        # this logic will create some entries with < 6mo intervals, but this is only due to the abover grouper function using a slightly different calendar\n",
    "        temp['INFODT'] = dates\n",
    "        temp['PATNO'] = patno\n",
    "        temp.drop(columns=['level_1'], inplace=True)\n",
    "\n",
    "        result = pd.concat([result, temp], ignore_index=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPDRS3 = \"data/MDS-UPDRS_Part_III_10Jun2024.csv\"\n",
    "patient_status = \"data/Participant_Status_03Jun2024.csv\"\n",
    "\n",
    "df3 = pd.read_csv(UPDRS3)\n",
    "df_pat_stat = pd.read_csv(patient_status) #patient status data\n",
    "df3 = df3.dropna(subset=['NP3TOT']).reset_index() # will keep for now, might need to include nans\n",
    "df3['INFODT'] = pd.to_datetime(df3['INFODT'], format=\"%m/%Y\") #reformat INFODT (Assesment Date) to date-time objects\n",
    "df3['PDSTATE'] =  df3['PDSTATE'].fillna(\"None\")\n",
    "df3 = df3[[\"PATNO\", \"EVENT_ID\", \"INFODT\", \"PDSTATE\", \"PAG_NAME\", \"NP3TOT\"]]\n",
    "\n",
    "desired_cols_df_pat = {'PATNO', 'COHORT', 'ENROLL_STATUS'}\n",
    "pat_filtered = df_pat_stat.drop(columns=set(df_pat_stat.columns) - desired_cols_df_pat)\n",
    "df3_full = pd.merge(df3, pat_filtered, on=\"PATNO\")\n",
    "df3_full = df3_full[df3_full['ENROLL_STATUS'].isin(['Enrolled', 'Withdrew', 'Complete'])]\n",
    "df3_full.drop(columns=['ENROLL_STATUS'], inplace=True)\n",
    "df3_full = df3_full.sort_values(['PATNO', 'INFODT'])\n",
    "\n",
    "# Partition our data sets\n",
    "upd3_control = df3_full[df3_full['COHORT'] == 2]\n",
    "upd3_PD = df3_full[df3_full['COHORT'] == 1]\n",
    "upd3_PD_nan = upd3_PD[(upd3_PD['PDSTATE'] != 'ON') & (upd3_PD['PDSTATE'] != 'OFF') & (upd3_PD['PAG_NAME'] != 'NUPDR3OF') & (upd3_PD['PAG_NAME'] != 'NUPDR3ON')].reset_index(drop=True)\n",
    "upd3_PD_off = upd3_PD[(upd3_PD['PDSTATE'] == 'OFF') | (upd3_PD['PAG_NAME'] == 'NUPDR3OF')].reset_index(drop=True)\n",
    "upd3_PD_on = upd3_PD[(upd3_PD['PDSTATE'] == 'ON') | (upd3_PD['PAG_NAME'] == 'NUPDR3ON')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on Median Time interpolation\n",
    "- Results below will be the same for both, as they use exactly the same logic on the grouper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res_mean': [116.46666666666667, 121.0], 'res_rand': [116.46666666666667, 121.0]}\n"
     ]
    }
   ],
   "source": [
    "res_mean = process_mean_intervals(interpolate_same_month(upd3_PD_nan, method='mean'), blocks=3, keep_small_intervals=True)\n",
    "res_rand = process_random_intervals(interpolate_same_month(upd3_PD_nan, method='rand'), blocks=3, keep_small_intervals=True)\n",
    "\n",
    "sub_optimal_time_deltas = {\"res_mean\": [res_mean[(res_mean['INFODT'] < 180) & (res_mean['INFODT'] > 0)]['INFODT'].mean(),\n",
    "                           res_mean[(res_mean['INFODT'] < 180) & (res_mean['INFODT'] > 0)]['INFODT'].median()],\n",
    "                           \"res_rand\": [res_rand[(res_rand['INFODT'] < 180) & (res_rand['INFODT'] > 0)]['INFODT'].mean(),\n",
    "                           res_rand[(res_rand['INFODT'] < 180) & (res_rand['INFODT'] > 0)]['INFODT'].median()]}\n",
    "\n",
    "print(sub_optimal_time_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Base-Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n",
      "/var/folders/3f/j_4mwg8n6c137n0zbqfb_rbc0000gn/T/ipykernel_6967/380767121.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, temp], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Simple stratified Cross Validation testing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipline Data Sets\n",
    "nan = interpolate_same_month(upd3_PD_nan, 'rand')\n",
    "off = interpolate_same_month(upd3_PD_off, 'rand')\n",
    "on = interpolate_same_month(upd3_PD_on, 'rand')\n",
    "control = interpolate_same_month(upd3_control, 'rand')\n",
    "\n",
    "#BASELINES RANDOM\n",
    "base_nan_rand = np.std(nan['NP3TOT'])\n",
    "base_off_rand = np.std(off['NP3TOT'])\n",
    "base_on_rand  = np.std(on['NP3TOT'])\n",
    "base_control_rand = np.std(control['NP3TOT'])\n",
    "\n",
    "PD_nan_rand = pivot_wide(process_random_intervals(nan, 3, keep_small_intervals=True))\n",
    "PD_off_rand = pivot_wide(process_random_intervals(off, 3, keep_small_intervals=True))\n",
    "PD_on_rand = pivot_wide(process_random_intervals(on, 3, keep_small_intervals=True))\n",
    "control_rand = pivot_wide(process_random_intervals(control, 3, keep_small_intervals=True))\n",
    "\n",
    "#DE-NOISED\n",
    "nan_mean = interpolate_same_month(upd3_PD_nan, 'mean')\n",
    "off_mean = interpolate_same_month(upd3_PD_off, 'mean')\n",
    "on_mean = interpolate_same_month(upd3_PD_on, 'mean')\n",
    "control_mean = interpolate_same_month(upd3_control, 'mean')\n",
    "\n",
    "base_nan_mean = np.std(nan_mean['NP3TOT'])\n",
    "base_off_mean = np.std(off_mean['NP3TOT'])\n",
    "base_on_mean  = np.std(on_mean['NP3TOT'])\n",
    "base_control_mean = np.std(control_mean['NP3TOT'])\n",
    "\n",
    "PD_nan_mean = pivot_wide(process_mean_intervals(nan_mean, 3, keep_small_intervals=True))\n",
    "PD_off_mean = pivot_wide(process_mean_intervals(off_mean, 3, keep_small_intervals=True))\n",
    "PD_on_mean = pivot_wide(process_mean_intervals(on_mean, 3, keep_small_intervals=True))\n",
    "control_mean = pivot_wide(process_mean_intervals(control_mean, 3, keep_small_intervals=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(df:pd.DataFrame, base_line: float, identifier: str = \"DEFAULT\", folds = 5):\n",
    "    X = df.iloc[: , : len(df.columns)-1]\n",
    "    y = df.iloc[: , len(df.columns)-1 : ]\n",
    "\n",
    "    pipe_rf = Pipeline(steps=[('model', RandomForestRegressor())])\n",
    "    pipe_ridge = Pipeline(steps=[('model', Ridge())])\n",
    "    # .values will give the values in a numpy array (shape: (n,1))\n",
    "    # .ravel will convert that array shape to (n, ) (i.e. flatten it)\n",
    "    score_test_rf = -1 * cross_val_score(pipe_rf, X, y.values.ravel(), cv=folds, scoring=\"neg_root_mean_squared_error\")\n",
    "    score_test_ridge = -1 * cross_val_score(pipe_ridge, X, y.values.ravel(), cv=folds, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    print(f\"Testing {identifier} Model\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"STD(NP3TOT) {identifier}: {base_line}\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    print(f\"Startings models, Simple Cross Validation, k = {folds}, VS std(UPDRS): \\n\")\n",
    "    print(\" Ridge Regression RMSE by fold: \", score_test_ridge)\n",
    "    print(\" Random Forest RMSE by fold: \", score_test_rf, \"\\n\")\n",
    "    print(f\" Ridge Regression mean RMSE: {score_test_ridge.mean()}\", '\\n', f\"Random Forest, default 5-nodes, mean RMSE: {score_test_rf.mean()}\")\n",
    "\n",
    "    return [score_test_rf.mean(), score_test_ridge.mean()]\n",
    "\n",
    "def compare_models(df_mean: pd.DataFrame, df_rand: pd.DataFrame, base_mean: float, base_rand: float):\n",
    "    mean = test_models(df_mean, base_mean, \"MEAN\")\n",
    "    rand = test_models(df_rand, base_rand, \"Random Selection\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Comparing Models\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"Mean Model: {mean}\")\n",
    "    print(f\"Random Model: {rand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MEAN Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) MEAN: 10.364208177895836\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [6.91107141 5.58562419 6.08251447 6.20402827 5.90124459]\n",
      " Random Forest RMSE by fold:  [7.22851021 6.10489088 6.5504219  6.43666519 6.07639646] \n",
      "\n",
      " Ridge Regression mean RMSE: 6.136896584608074 \n",
      " Random Forest, default 5-nodes, mean RMSE: 6.479376926535873\n",
      "Testing Random Selection Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) Random Selection: 10.362838637802493\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [8.70071038 6.68757251 7.94589857 6.52360109 5.56118326]\n",
      " Random Forest RMSE by fold:  [9.0342922  6.86086849 8.54392526 6.76253569 6.41627607] \n",
      "\n",
      " Ridge Regression mean RMSE: 7.0837931632457725 \n",
      " Random Forest, default 5-nodes, mean RMSE: 7.523579542101658\n",
      "----------------------------------------------------------------\n",
      "Comparing Models\n",
      "----------------------------------------------------------------\n",
      "Mean Model: [6.479376926535873, 6.136896584608074]\n",
      "Random Model: [7.523579542101658, 7.0837931632457725]\n"
     ]
    }
   ],
   "source": [
    "compare_models(PD_nan_mean, PD_nan_rand, base_nan_mean, base_nan_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of De-noising\n",
    "- Have some improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_nan - Random Selection Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_nan - Random Selection: 10.362838637802493\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [8.70071038 6.68757251 7.94589857 6.52360109 5.56118326]\n",
      " Random Forest RMSE by fold:  [9.04437412 6.93225207 8.41778543 6.67907911 6.36091929] \n",
      "\n",
      " Ridge Regression mean RMSE: 7.0837931632457725 \n",
      " Random Forest, default 5-nodes, mean RMSE: 7.486882004401413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.486882004401413, 7.0837931632457725]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_nan_rand, base_nan_rand, \"PD_nan - Random Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_nan - mean Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_nan - mean: 10.364208177895836\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [6.91107141 5.58562419 6.08251447 6.20402827 5.90124459]\n",
      " Random Forest RMSE by fold:  [7.23937371 6.09191799 6.38802719 6.49733997 6.07188633] \n",
      "\n",
      " Ridge Regression mean RMSE: 6.136896584608074 \n",
      " Random Forest, default 5-nodes, mean RMSE: 6.4577090381394395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.4577090381394395, 6.136896584608074]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_nan_mean, base_nan_mean, \"PD_nan - mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_off - Random Selection Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_off - Random Selection: 3.6578525543510483\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [11.66845595 10.76481325 13.69169393 12.43510625  9.1594407 ]\n",
      " Random Forest RMSE by fold:  [12.16504084 12.64765307 15.00681165 13.60191722 10.97588654] \n",
      "\n",
      " Ridge Regression mean RMSE: 11.54390201663226 \n",
      " Random Forest, default 5-nodes, mean RMSE: 12.87946186493274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.87946186493274, 11.54390201663226]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_off_rand, base_control_rand, \"PD_off - Random Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_off - Mean Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_off - Mean: 14.29971406609739\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [ 8.63199575  9.14592362 10.39531376 12.40404826  8.25601125]\n",
      " Random Forest RMSE by fold:  [ 9.26253158  9.88510082 11.24920481 12.33954202  8.90627716] \n",
      "\n",
      " Ridge Regression mean RMSE: 9.766658527427321 \n",
      " Random Forest, default 5-nodes, mean RMSE: 10.328531276973072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.328531276973072, 9.766658527427321]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_off_mean, base_off_mean, \"PD_off - Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_on - Random Selection Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_on - Random Selection: 12.3650437267417\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [ 9.45682032 10.04298727  9.62934988 11.32655765  8.07995708]\n",
      " Random Forest RMSE by fold:  [11.14985652 10.49618616 11.30439734 12.07316683  8.57845384] \n",
      "\n",
      " Ridge Regression mean RMSE: 9.70713444051464 \n",
      " Random Forest, default 5-nodes, mean RMSE: 10.720412137123907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.720412137123907, 9.70713444051464]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_on_rand, base_on_rand, \"PD_on - Random Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PD_on - mean Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) PD_on - mean: 12.36565687843349\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [8.76227789 9.10094415 8.36509702 8.55911554 7.67864504]\n",
      " Random Forest RMSE by fold:  [9.66598723 9.44188011 8.98107257 9.14247181 7.92152757] \n",
      "\n",
      " Ridge Regression mean RMSE: 8.493215928304085 \n",
      " Random Forest, default 5-nodes, mean RMSE: 9.030587857706752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.030587857706752, 8.493215928304085]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(PD_on_mean, base_on_mean, \"PD_on - mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Control - Random Selection Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) Control - Random Selection: 3.6578525543510483\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [4.55208934 6.26859076 2.75340235 3.10779985 1.80226811]\n",
      " Random Forest RMSE by fold:  [4.07982884 6.69047586 6.21206404 3.15122124 1.98719542] \n",
      "\n",
      " Ridge Regression mean RMSE: 3.69683008370965 \n",
      " Random Forest, default 5-nodes, mean RMSE: 4.424157083317743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.424157083317743, 3.69683008370965]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(control_rand, base_control_rand, \"Control - Random Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Control - mean Model\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) Control - mean: 3.6681035622266616\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [4.3711837  4.8588078  1.92876078 2.54946409 2.20902345]\n",
      " Random Forest RMSE by fold:  [4.37547551 4.78111847 1.87291086 2.50478465 2.17510759] \n",
      "\n",
      " Ridge Regression mean RMSE: 3.1834479658368107 \n",
      " Random Forest, default 5-nodes, mean RMSE: 3.1418794166724355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1418794166724355, 3.1834479658368107]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(control_mean, base_control_mean, \"Control - mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
