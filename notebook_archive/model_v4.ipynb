{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#PLOT & MATH LIBS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest TO DO in light of info from Tristan\n",
    "##### ON OFF States\n",
    "1. Same idea as originally (one-hot) BUT:\n",
    "   1. Keep Same Month Visits, then select randomly from total visits\n",
    "   2. In the case with both ON & OFF for the same visit\n",
    "      1. Record the scores in an extra column so, u_on_0, u_off_o oooooorrrr\n",
    "      2. **Duplicate the row, keeping all other entries the same, but with the ON & OFF entry different for each**\n",
    "      3. Make Sure both of either same month or ON & OFF are in the same training or validation set\n",
    "   3. Compare One-to-one with completely random selection from fist analysis (but including same month visits)\n",
    "\n",
    "\n",
    "##### De-noising\n",
    "1. Use calendar approach:\n",
    "   1. Divide the PATNO's interval into 3 non-overlapping >6mo periods\n",
    "   2. Take the mean of each interval as the interval UPDRS score\n",
    "   3. Take the mean(median Date) as the date for that interval (if >1 date within!)\n",
    "2. (Tristan's) Slightly Different:\n",
    "   1. Intervals defined as:\n",
    "      1.  t_0 + 6mo\n",
    "      2.  (median date by index) = (index(t_0) + index(t_f) / 2) +/- 3mo\n",
    "      3.  t_f - 6mo \n",
    "  1.  Same interval date and mean logic\n",
    "3.  Compare results vs calendar approach for random choice for both (i.e. random selection within same intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_same_month(df: pd.DataFrame, method = 'rand') -> pd.DataFrame:\n",
    "    # Select maximum score from same month measurements\n",
    "    temp_df = df.copy()\n",
    "    temp_df['YEAR_MONTH'] = temp_df['INFODT'].dt.to_period('M')\n",
    "\n",
    "    #takes random selctions/maximum/minimum/mean of values which share same month and year\n",
    "    if method == 'rand':\n",
    "        sample = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].apply(lambda x: x.sample(1)).reset_index()\n",
    "        result = pd.merge(temp_df, sample, on=['PATNO', 'YEAR_MONTH', 'NP3TOT'])\n",
    "\n",
    "        result.drop(columns=['YEAR_MONTH', 'level_2'], inplace=True)\n",
    "        return result.drop_duplicates(subset=['PATNO', 'INFODT']).reset_index(drop=True)\n",
    "\n",
    "    elif method == 'min':\n",
    "        #result = pd.merge(temp_df, temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].min(), on=['PATNO', 'YEAR_MONTH', 'NP3TOT'])\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('min')\n",
    "    elif method == 'max':\n",
    "        #result = pd.merge(temp_df, temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].max(), on=['PATNO', 'YEAR_MONTH', 'NP3TOT'])\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('max')\n",
    "    else:\n",
    "        #result = pd.merge(temp_df, temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].mean(), on=['PATNO', 'YEAR_MONTH', 'NP3TOT'])\n",
    "        temp_df['NP3TOT'] = temp_df.groupby(['PATNO', 'YEAR_MONTH'])['NP3TOT'].transform('mean')\n",
    "\n",
    "    \n",
    "    temp_df.drop(columns=['YEAR_MONTH'], inplace=True)\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "    return temp_df.drop_duplicates(subset=['PATNO', 'INFODT'])\n",
    "\n",
    "def pivot_wide(input: pd.DataFrame, cols: int = 3) -> pd.DataFrame:\n",
    "    \n",
    "    time_df = input[['PATNO', 'time_delta', 'time_index']]\n",
    "\n",
    "    score_wide = input.pivot(\n",
    "        index='PATNO',\n",
    "        columns='time_index',\n",
    "        values='score'\n",
    "    ).reset_index()\n",
    "\n",
    "    time_wide = time_df.pivot(\n",
    "        index='PATNO',\n",
    "        columns=\"time_index\",\n",
    "        values='time_delta'\n",
    "    ).reset_index()\n",
    "\n",
    "    score_wide.columns = ['PATNO'] + [f'u{i}' for i in range(cols)] # resets score column names correctly\n",
    "    time_wide.columns = ['PATNO'] + [f't{i}' for i in range(cols)] # resets time_index column names accordingly\n",
    "\n",
    "    merged = pd.merge(score_wide, time_wide, on='PATNO') # use PATNO to merge\n",
    "    #print(merged)\n",
    "    #merged.drop(columns='PATNO', inplace=True) # drop PATNO, no longer needed\n",
    "\n",
    "    new_cols = []\n",
    "    for i in range(cols): # re order columns for ML piplines\n",
    "        new_cols.append(f't{i}')\n",
    "        new_cols.append(f'u{i}')\n",
    "\n",
    "    merged = merged[new_cols]\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def process_dates_caller(input: pd.DataFrame, entries: int = 3, same_month_flag = False) -> pd.DataFrame:\n",
    "    # helps maintain random states of dataframes to compare to baselines, default is to assume input is already interpolated\n",
    "    df = interpolate_same_month(input, 'rand') if same_month_flag else input\n",
    "\n",
    "    patnos = df['PATNO'].unique().tolist()\n",
    "    df = input.copy()\n",
    "    limit = pd.Timedelta(6*30, unit='D') # 180 days ~ 6mo\n",
    "    date_chunks = []\n",
    "\n",
    "    for id in patnos:\n",
    "\n",
    "        visits = df[df['PATNO'] == id]['INFODT'].tolist()\n",
    "        soln = []\n",
    "        lim = 0\n",
    "\n",
    "        if len(visits) < entries:\n",
    "            #print(f\"Not Enough Entries for ID: {id}\")\n",
    "            continue\n",
    "\n",
    "        sub_df = df[df['PATNO'] == id]\n",
    "        random.seed(10)\n",
    "        while True:\n",
    "            soln = np.random.choice(visits, entries, replace=False)\n",
    "            if (soln[1] - soln[0]) > limit and (soln[2] - soln[1]) > limit:\n",
    "                break\n",
    "            if lim > 100:\n",
    "                #print(f\"No Possible Calendar Combination Found for ID: {id}\")\n",
    "                break\n",
    "            lim += 1\n",
    "        \n",
    "        if lim < 100:\n",
    "            for i in range(entries):\n",
    "                date_chunks.append([id, sub_df.loc[sub_df['INFODT'] == soln[i], 'INFODT'].values[0], sub_df.loc[sub_df['INFODT'] == soln[i], 'NP3TOT'].values[0], sub_df.loc[sub_df['INFODT'] == soln[i], 'PDSTATE'].values[0]])     \n",
    "\n",
    "    res = pd.DataFrame(date_chunks, columns=['PATNO', 'INFODT', 'score', 'PDSTATE'])\n",
    "\n",
    "    # Prepare dataframe for pivoting\n",
    "\n",
    "    res['time_delta'] = (\n",
    "        res.groupby('PATNO')['INFODT']\n",
    "        .transform(\n",
    "            lambda x: (x - x.min()) / np.timedelta64(30, 'D')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    res['time_index'] = (\n",
    "            res.groupby('PATNO')['INFODT']\n",
    "            .rank(method='first')\n",
    "            .astype(int)-1\n",
    "        ) \n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def pivot_wide_with_states(input: pd.DataFrame, cols: int = 3) -> pd.DataFrame:\n",
    "    \n",
    "    time_df = input[['PATNO', 'time_delta', 'time_index']]\n",
    "    \n",
    "    score_wide = input.pivot(\n",
    "        index='PATNO',\n",
    "        columns='time_index',\n",
    "        values='score'\n",
    "    ).reset_index()\n",
    "\n",
    "    time_wide = time_df.pivot(\n",
    "        index='PATNO',\n",
    "        columns=\"time_index\",\n",
    "        values='time_delta'\n",
    "    ).reset_index()\n",
    "\n",
    "    off_wide = input.pivot(\n",
    "        index='PATNO',\n",
    "        columns='time_index',\n",
    "        values='OFF'\n",
    "    ).reset_index()\n",
    "\n",
    "    on_wide = input.pivot(\n",
    "        index='PATNO',\n",
    "        columns='time_index',\n",
    "        values='ON'\n",
    "    ).reset_index()\n",
    "\n",
    "    score_wide.columns = ['PATNO'] + [f'u{i}' for i in range(cols)] # resets score column names correctly\n",
    "    time_wide.columns = ['PATNO'] + [f't{i}' for i in range(cols)] # resets time_index column names accordingly\n",
    "    off_wide.columns = ['PATNO'] + [f'off_{i}' for i in range(cols)] # resets time_index column names accordingly\n",
    "    on_wide.columns = ['PATNO'] + [f'on_{i}' for i in range(cols)] # resets time_index column names accordingly\n",
    "\n",
    "    #merged = pd.merge(score_wide, time_wide, on='PATNO') # use PATNO to merge\n",
    "    #print(merged)\n",
    "    #merged.drop(columns='PATNO', inplace=True) # drop PATNO, no longer needed\n",
    "\n",
    "    merged = pd.concat([score_wide, time_wide, off_wide, on_wide], axis=1)\n",
    "    merged.drop(columns='PATNO', inplace=True)\n",
    "\n",
    "\n",
    "    new_cols = []\n",
    "    for i in range(cols): # re order columns for ML piplines\n",
    "        new_cols.append(f't{i}')\n",
    "        new_cols.append(f'off_{i}')\n",
    "        new_cols.append(f'on_{i}')\n",
    "        new_cols.append(f'u{i}')\n",
    "\n",
    "    merged = merged[new_cols]\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPDRS3 = \"data/MDS-UPDRS_Part_III_10Jun2024.csv\"\n",
    "patient_status = \"data/Participant_Status_03Jun2024.csv\"\n",
    "\n",
    "df3 = pd.read_csv(UPDRS3)\n",
    "df_pat_stat = pd.read_csv(patient_status) #patient status data\n",
    "df3 = df3.dropna(subset=['NP3TOT']).reset_index() # will keep for now, might need to include nans\n",
    "df3['INFODT'] = pd.to_datetime(df3['INFODT'], format=\"%m/%Y\") #reformat INFODT (Assesment Date) to date-time objects\n",
    "df3['PDSTATE'] =  df3['PDSTATE'].fillna(\"None\")\n",
    "df3 = df3[[\"PATNO\", \"EVENT_ID\", \"INFODT\", \"PDSTATE\", \"PAG_NAME\", \"NP3TOT\"]]\n",
    "\n",
    "desired_cols_df_pat = {'PATNO', 'COHORT', 'ENROLL_STATUS'}\n",
    "pat_filtered = df_pat_stat.drop(columns=set(df_pat_stat.columns) - desired_cols_df_pat)\n",
    "df3_full = pd.merge(df3, pat_filtered, on=\"PATNO\")\n",
    "df3_full = df3_full[df3_full['ENROLL_STATUS'].isin(['Enrolled', 'Withdrew', 'Complete'])]\n",
    "df3_full.drop(columns=['ENROLL_STATUS'], inplace=True)\n",
    "df3_full = df3_full.sort_values(['PATNO', 'INFODT'])\n",
    "\n",
    "# Partition our data sets\n",
    "upd3_control = df3_full[df3_full['COHORT'] == 2]\n",
    "upd3_PD = df3_full[df3_full['COHORT'] == 1]\n",
    "upd3_PD_nan = upd3_PD[(upd3_PD['PDSTATE'] != 'ON') & (upd3_PD['PDSTATE'] != 'OFF') & (upd3_PD['PAG_NAME'] != 'NUPDR3OF') & (upd3_PD['PAG_NAME'] != 'NUPDR3ON')]\n",
    "upd3_PD_off = upd3_PD[(upd3_PD['PDSTATE'] == 'OFF') | (upd3_PD['PAG_NAME'] == 'NUPDR3OF')]\n",
    "upd3_PD_on = upd3_PD[(upd3_PD['PDSTATE'] == 'ON') | (upd3_PD['PAG_NAME'] == 'NUPDR3ON')]\n",
    "# Data set of interest...\n",
    "upd3_PD_off_on = upd3_PD[(upd3_PD['PDSTATE'] == 'ON') | (upd3_PD['PDSTATE'] == 'OFF') | (upd3_PD['PAG_NAME'] == 'NUPDR3OF') | (upd3_PD['PAG_NAME'] == 'NUPDR3ON')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO \n",
    "2. Can we use PD States as conditional features in our model?\n",
    "   1. Format would be similar to the random one, but with a state_flag included: \n",
    "   2. t_0 | u_0 | s_0 | t_1 | ...\n",
    "   3. OR another way: t_0 | ON_0 | OFF_0 | u_0 | .... where ON,OFF are in [0,1]\n",
    "3. Can we use the Error Term from same-month visits in our model? Contidional Regression: **Looks to be a Ridge regression on descrete variables**\n",
    "4. **Find and adjust model params (definitely ask Tristan or others for guidance here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including states with One-Hot-encoding\n",
    "1. Structure is time, OFF state, ON state, and score (all) at time i : t0 | off_0 | on_0 | u0 | ...\n",
    "\n",
    "**Observations**\n",
    "1. Performs worse than examining the states separately, compared to the Datasets NP3TOT std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd3_PD_off_on = upd3_PD[(upd3_PD['PDSTATE'] == 'ON') | (upd3_PD['PDSTATE'] == 'OFF') | (upd3_PD['PAG_NAME'] == 'NUPDR3OF') | (upd3_PD['PAG_NAME'] == 'NUPDR3ON')].reset_index(drop=True)\n",
    "PD_on_off = interpolate_same_month(upd3_PD_off_on, method='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT</th>\n",
       "      <th>score</th>\n",
       "      <th>PDSTATE</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>time_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>33.466667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3002</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>22.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3002</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>29.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>164491</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>164491</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>13.233333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>182341</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>182341</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>182341</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>27.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PATNO     INFODT  score PDSTATE  time_delta  time_index\n",
       "0       3001 2013-09-01   25.0      ON    0.000000           0\n",
       "1       3001 2014-11-01   42.0      ON   14.200000           1\n",
       "2       3001 2016-06-01   26.0      ON   33.466667           2\n",
       "3       3002 2013-04-01   22.0      ON    0.000000           0\n",
       "4       3002 2015-03-01   29.0      ON   23.300000           1\n",
       "...      ...        ...    ...     ...         ...         ...\n",
       "2083  164491 2023-11-01    7.0      ON    6.133333           1\n",
       "2084  164491 2024-06-01    9.0      ON   13.233333           2\n",
       "2085  182341 2023-01-01   10.0      ON    0.000000           0\n",
       "2086  182341 2023-07-01   14.0      ON    6.033333           1\n",
       "2087  182341 2024-01-01   27.0      ON   12.166667           2\n",
       "\n",
       "[2088 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_on_off = process_dates_caller(PD_on_off, entries=3, same_month_flag=True)\n",
    "test_on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0</th>\n",
       "      <th>off_0</th>\n",
       "      <th>on_0</th>\n",
       "      <th>u0</th>\n",
       "      <th>t1</th>\n",
       "      <th>off_1</th>\n",
       "      <th>on_1</th>\n",
       "      <th>u1</th>\n",
       "      <th>t2</th>\n",
       "      <th>off_2</th>\n",
       "      <th>on_2</th>\n",
       "      <th>u2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>98.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.433333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>696 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t0  off_0  on_0    u0         t1  off_1  on_1    u1         t2  off_2  \\\n",
       "0    0.0      0     1  25.0  14.200000      0     1  42.0  33.466667      0   \n",
       "1    0.0      0     1  22.0  23.300000      0     1  29.0  36.533333      0   \n",
       "2    0.0      0     1  53.0  12.200000      0     1  39.0  98.400000      0   \n",
       "3    0.0      0     1  39.0   9.100000      0     1  18.0  58.800000      1   \n",
       "4    0.0      1     0  35.0  13.166667      0     1  39.0  28.433333      0   \n",
       "..   ...    ...   ...   ...        ...    ...   ...   ...        ...    ...   \n",
       "691  0.0      0     1  14.0   7.133333      1     0  13.0  13.233333      1   \n",
       "692  0.0      1     0  16.0   6.033333      0     1   9.0  12.166667      0   \n",
       "693  0.0      0     1   7.0   6.033333      1     0  10.0  12.166667      1   \n",
       "694  0.0      0     1  10.0   6.133333      0     1   7.0  13.233333      0   \n",
       "695  0.0      0     1  10.0   6.033333      0     1  14.0  12.166667      0   \n",
       "\n",
       "     on_2    u2  \n",
       "0       1  26.0  \n",
       "1       1  30.0  \n",
       "2       1  43.0  \n",
       "3       0  58.0  \n",
       "4       1  38.0  \n",
       "..    ...   ...  \n",
       "691     0  11.0  \n",
       "692     1  14.0  \n",
       "693     0  12.0  \n",
       "694     1   9.0  \n",
       "695     1  27.0  \n",
       "\n",
       "[696 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_hot = pd.get_dummies(test_on_off['PDSTATE'], dtype=int)\n",
    "on_hot.drop(columns=['None'], inplace=True)\n",
    "PD_on_off_encoded = pd.merge(test_on_off, on_hot, left_index=True, right_index=True)\n",
    "res_on_off = pivot_wide_with_states(PD_on_off_encoded, 3)\n",
    "res_on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple stratified Cross Validation testing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipline Data Sets\n",
    "PD_w_states = interpolate_same_month(upd3_PD_nan, 'rand')\n",
    "\n",
    "#BASELINES\n",
    "base_w_states = np.std(PD_w_states['NP3TOT'])\n",
    "\n",
    "# Processing and pivoting dataset\n",
    "PD_w_states = process_dates_caller(PD_on_off, entries=3, same_month_flag=True)\n",
    "on_hot = pd.get_dummies(PD_w_states['PDSTATE'], dtype=int)\n",
    "on_hot.drop(columns=['None'], inplace=True)\n",
    "PD_on_off_encoded = pd.merge(PD_w_states, on_hot, left_index=True, right_index=True)\n",
    "res_on_off = pivot_wide_with_states(PD_on_off_encoded, 3)\n",
    "\n",
    "def test_model(X, y, folds = 5):\n",
    "    pipe_rf = Pipeline(steps=[('model', RandomForestRegressor())])\n",
    "    pipe_ridge = Pipeline(steps=[('model', Ridge())])\n",
    "    # .values will give the values in a numpy array (shape: (n,1))\n",
    "    # .ravel will convert that array shape to (n, ) (i.e. flatten it)\n",
    "    score_test_rf = -1 * cross_val_score(pipe_rf, X, y.values.ravel(), cv=folds, scoring=\"neg_root_mean_squared_error\")\n",
    "    score_test_ridge = -1 * cross_val_score(pipe_ridge, X, y.values.ravel(), cv=folds, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    print(\"Baselines\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"STD(NP3TOT) With States: {base_w_states}\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    print(f\"Startings models, Simple Cross Validation, k = {folds}, VS std(UPDRS): \\n\")\n",
    "    print(\" Ridge Regression RMSE by fold: \", score_test_ridge)\n",
    "    print(\" Random Forest RMSE by fold: \", score_test_rf, \"\\n\")\n",
    "    print(f\" Ridge Regression mean RMSE: {score_test_ridge.mean()}\", '\\n', f\"Random Forest, default 5-nodes, mean RMSE: {score_test_rf.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 11) (696, 1) \n",
      "\n",
      "1st Run: PD With States\n",
      "Baselines\n",
      "----------------------------------------------------------------\n",
      "STD(NP3TOT) With States: 10.364208177895836\n",
      "----------------------------------------------------------------\n",
      "Startings models, Simple Cross Validation, k = 5, VS std(UPDRS): \n",
      "\n",
      " Ridge Regression RMSE by fold:  [11.37335506 10.60562307 12.07617329 12.86087622  9.10953348]\n",
      " Random Forest RMSE by fold:  [12.98462156 11.25990815 13.03134889 13.41765521  9.99748148] \n",
      "\n",
      " Ridge Regression mean RMSE: 11.205112221018421 \n",
      " Random Forest, default 5-nodes, mean RMSE: 12.13820305957007\n"
     ]
    }
   ],
   "source": [
    "X = res_on_off.iloc[: , : len(res_on_off.columns)-1]\n",
    "y = res_on_off.iloc[: , len(res_on_off.columns)-1 : ]\n",
    "\n",
    "print(X.shape, y.shape, \"\\n\")\n",
    "print(\"1st Run: PD With States\")\n",
    "test_model(X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
